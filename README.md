# üö® End-to-End Fraud Detection System with MLOps

A production-style **Machine Learning + MLOps** project that demonstrates the full lifecycle of an ML system ‚Äî from raw data ingestion to deployment, monitoring, and automated retraining.

This project is built to reflect **real-world engineering practices**, not just notebook experiments.

---

## üìå What this project shows

* How to build a **complete ML pipeline**
* How to track experiments with **MLflow**
* How to deploy models with **FastAPI**
* How to log predictions in production
* How to detect **data drift**
* How to trigger **automated retraining**
* How to manage ML projects the **industry way**

---

## üèóÔ∏è System Architecture

```
Raw Data
   ‚îÇ
   ‚ñº
Data Ingestion  ‚îÄ‚îÄ‚ñ∂ Cleaning ‚îÄ‚îÄ‚ñ∂ Feature Engineering
                                   ‚îÇ
                                   ‚ñº
                             Model Training
                         (LogReg, RF, XGBoost)
                                   ‚îÇ
                                   ‚ñº
                           MLflow Tracking
                           + Model Registry
                                   ‚îÇ
                                   ‚ñº
                           FastAPI Inference
                               /predict
                                   ‚îÇ
                                   ‚ñº
                         Prediction Logging
                                   ‚îÇ
                                   ‚ñº
                         Drift Detection
                               (Evidently)
                                   ‚îÇ
                                   ‚ñº
                       Automated Retraining
```

---

## üß† Models Used

* Logistic Regression
* Random Forest
* XGBoost

Evaluation metrics:

* ROC-AUC
* Precision
* Recall
* F1-score

---

## üìÅ Project Structure

```
mlops-fraud-detection/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/        # Data loading & validation
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/   # Cleaning & missing value handling
‚îÇ   ‚îú‚îÄ‚îÄ features/        # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ training/        # Model training + MLflow
‚îÇ   ‚îú‚îÄ‚îÄ serving/         # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/      # Drift detection
‚îÇ   ‚îî‚îÄ‚îÄ retraining/      # Automated retrain pipeline
‚îÇ
‚îú‚îÄ‚îÄ data/                # (ignored in git)
‚îú‚îÄ‚îÄ logs/                # Prediction logs
‚îú‚îÄ‚îÄ reports/             # Drift reports
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

---

## ‚öôÔ∏è Tech Stack

* **Python**
* **scikit-learn**
* **XGBoost**
* **MLflow**
* **FastAPI**
* **Evidently AI**
* **Git + GitHub**

---

## üöÄ How to Run Locally

### 1Ô∏è‚É£ Create environment

```bash
conda create -n fraud python=3.10
conda activate fraud
```

### 2Ô∏è‚É£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## üß© Pipeline Execution

### Data Ingestion

```bash
python src/ingestion/ingest.py
```

### Cleaning

```bash
python src/preprocessing/clean.py
```

### Feature Engineering

```bash
python src/features/build_features.py
```

### Train Models

```bash
python src/training/train_with_mlflow.py
```

### Register Best Model

```bash
python src/training/register_model.py
```

---

## üîç MLflow UI

```bash
mlflow ui
```

Open:
üëâ [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## üåê Run API

```bash
uvicorn src.serving.api:app --reload
```

API will be live at:
üëâ [http://127.0.0.1:8000](http://127.0.0.1:8000)

Docs:
üëâ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## üìÆ Example Prediction

POST `/predict`

```json
{
  "features": [0.13, 0.44, 1.02, ...]
}
```

Response:

```json
{
  "fraud_probability": 0.73,
  "fraud_prediction": 1,
  "latency_sec": 0.42
}
```

---

## üìä Monitoring & Drift Detection

```bash
python src/monitoring/drift_check.py
```

Output:

```
reports/drift_report.txt
```

Contains:

* Drift detected or not
* Feature checked
* Monitoring status

---

## üîÅ Automated Retraining

```bash
python src/retraining/retrain_pipeline.py
```

What it does:

1. Reads drift report
2. If drift detected ‚Üí retrains models
3. Logs new run in MLflow
4. Registers new model version

---

## üßë‚Äçüíª What I learned

* How production ML differs from notebooks
* How to structure real ML projects
* How MLflow works in practice
* How to serve ML models reliably
* Why monitoring & retraining matter
* How real MLOps pipelines are built

---

## üéØ Resume-ready Description

> Built an end-to-end fraud detection system with full MLOps lifecycle including data pipelines, MLflow-based experiment tracking, FastAPI deployment, prediction logging, drift detection using Evidently AI, and an automated retraining pipeline.

---

## ‚≠ê If you like this project

Give it a ‚≠ê on GitHub ‚Äî it helps a lot!
